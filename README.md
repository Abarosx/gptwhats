*Imagem gerada com a IA do Midjourney*
![Imagem gerada no Midjourney](https://miro.medium.com/max/4800/1*FyJQWP0fVMMHXhEa7M0kOQ.webp)

Este guia ir√° explicar como integrar o modelo de linguagem GPT-3 utilizado no ChatGPT com o WhatsApp. A integra√ß√£o permitir√° que usu√°rios interajam com o ChatGPT atrav√©s de mensagens de texto no WhatsApp, fornecendo respostas automatizadas baseadas em suas perguntas e comandos. O guia discutir√° os passos necess√°rios desde a configura√ß√£o at√© a integra√ß√£o. Vamos usar o Node.js com Javascript para criar o projeto e a biblioteca venom-bot para a integra√ß√£o com o Whatsapp.

![Chat GPT Logo](https://miro.medium.com/max/4800/1*HhDoR-hLcObJXSwDDEar4g.webp)

## Vantagens de integrar o modelo GPT-3 com Whatsapp

1. Conforto de utilizar a IA no Whatsapp
2. Qualquer pessoa pode mandar os comandos para a IA no privado ou em grupos que o contato que esteja rodando este servi√ßo estiver.
3. O filtro para perguntas politicamente incorretas est√° desligado ao comunicar diretamente com a API. ~~Seria isso uma vantagem?~~ üëÄ

Teste do filtro feito no pr√≥prio site do Chat GPT:
![Chat GPT Teste Filtro](https://miro.medium.com/max/4800/1*98irGe0GAlvlhkErKKw6iQ.webp)

Teste do filtro feito no Whatsapp utilizando a API:
![Chat GPT Teste Filtro Whatsapp](https://miro.medium.com/max/584/1*bZ6Wfjv7LA5kzUHOJnjMhQ.png)

## 1. Criando o projeto
O Node.js √© uma plataforma de desenvolvimento baseada em Javascript que permite criar aplica√ß√µes como APIs e servi√ßos. Ele foi baseado no interpretador V8 do Google permitindo assim rodar diretamente no servidor sem necessidade de um navegador para sua execu√ß√£o. Diferente do uso tradicional do Javascript, que √© restrito ao client-side, o Node.js permite aproveitar as vantagens do Javascript no desenvolvimento de aplica√ß√µes no server-side.

![Javascript Power](https://miro.medium.com/max/559/1*nSfk7VzjCNeBwzlpuf1n1g.jpeg)

### Passo 1.1: Instalando o Node.js e o npm
A primeira coisa que voc√™ precisa fazer √© instalar o Node.js em seu computador. Voc√™ pode baixar o instalador no site oficial do Node.js (https://nodejs.org/en/download/) e seguir as instru√ß√µes de instala√ß√£o. Uma vez que voc√™ instalou o Node.js, voc√™ tamb√©m ter√° o npm instalado automaticamente, o npm √© o gerenciador de pacotes do Node.js ele permite instalar e gerenciar bibliotecas e depend√™ncias. Para verificar se voc√™ tem o Node.js e o npm instalados corretamente, abra o prompt de comando e digite ‚Äúnode -v‚Äù e ‚Äúnpm -v‚Äù para ver as vers√µes instaladas.

### Passo 1.2: Criando um novo projeto
Depois de ter o Node.js e o npm instalados, voc√™ pode criar um novo projeto Node.js. Abra o prompt de comando e navegue at√© a pasta onde voc√™ deseja criar o projeto, digite ‚Äúnpm init‚Äù para iniciar o processo de cria√ß√£o, isso criar√° um arquivo package.json que cont√©m as informa√ß√µes do projeto, incluindo nome, vers√£o, depend√™ncias e scripts. Ele √© usado pelo npm para gerenciar as depend√™ncias do projeto.

```
# Primeiro crie a sua pasta com o nome do projeto
mkdir zap-gpt

# Entre na pasta criada 
cd zap-gpt

# Crie o arquivo package.json com o comando
npm init
```

Agora vamos adicionar em nosso package.json o ‚Äútype‚Äù como ‚Äúmodule‚Äù, assim a gente vai poder usar a syntax de import do ES6 Modules.

```
{
  "name": "zap-gpt",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "",
  "license": "ISC"
}
```

## 2. Instalando e configurando o venom-bot
Venom √© uma depend√™ncia desenvolvida com JavaScript para criar servi√ßos para WhatsApp como atendimento ao cliente automatizado, envio de m√≠dia, reconhecimento de frases baseado em intelig√™ncia artificial e todos os tipos de arquitetura de design para WhatsApp.

![Venom Bot Image](https://miro.medium.com/max/1400/1*cJSZ1y1RP9FrQgUZKag7vw.webp)

### Passo 2.1: Instala√ß√£o
Agora que voce j√° tem o arquivo package.json, j√° pode instalar as depend√™ncias do seu projeto. Voc√™ vai instal√°-lo digitando ‚Äúnpm install venom-bot‚Äù no prompt de comando.

```
# Instale venom-bot como uma dependencia do seu projeto
npm install venom-bot
```

### Passo 2.2: Configura√ß√£o
N√£o vou me atentar na estrutura√ß√£o das pastas neste guia, ent√£o vamos apenas criar um arquivo index.js dentro na raiz do projeto.

![Estrutura de pastas index.js](https://miro.medium.com/max/640/1*_ah8dQeNHiuLlcrn4IvKKw.webp)

No nosso arquivo index iremos criar uma nova sess√£o e chamar nossa fun√ß√£o start() ap√≥s a conex√£o ser feita com sucesso. Para que a gente possa observar qualquer evento disparado de mensagem no nosso whatsapp iremos chamar a fun√ß√£o onAnyMessage do client para que ele observe todas as mensagens enviadas incluindo as nossas, e passaremos como parametro uma function como callback para que seja executada sempre que uma nova mensagem for enviada, validaremos ent√£o o conte√∫do da mensagem, se o conte√∫do for ‚Äúhello‚Äù iremos enviar uma mensagem de volta ‚Äúü§ñ world üåé‚Äù.

```
import { create } from 'venom-bot'

create({
    session: 'chat-gpt',
    multidevice: true
})
    .then((client) => start(client))
    .catch((erro) => {
        console.log(erro)
    })

async function start(client) {
    const botText = "ü§ñ world üåé"
    // Da um console.log em message depois, tem muita coisa bacana
    client.onAnyMessage((message) => {
        if (message.body.toLowerCase() === "hello") {
            // message.from √© o n√∫mero do usu√°rio que enviou a msg "hello"
            client.sendText(message.from, botText)
        }
    })
}
```

### Passo 2.3: Testando a implementa√ß√£o
Execute o projeto com o comando ‚Äúnode .‚Äù em seu terminal, assim ele ir√° executar o arquivo nomeado como index no diretorio onde o comando foi executado. Ap√≥s aguardar alguns instantes ser√° gerado um QR Code que deve ser lido pelo aplicativo do Whatsapp. Em seu aplicativo toque em ‚ÄúMais op√ß√µes‚Äù ou ‚ÄúConfigura√ß√µes‚Äù, selecione ‚ÄúAparelhos conectados‚Äù e depois selecione a op√ß√£o ‚ÄúConectar um aparelho‚Äù para ler o QR Code gerado.

![Inicializa√ß√£o do projeto](https://miro.medium.com/max/640/1*wZGVeFhTmdzFV0b0deCBkg.webp)

Ap√≥s ler o QR Code ir√° aparecer no terminal o status *‚Äú‚úì [instance: Chat-GPT]: Connected‚Äù* indicando que a conex√£o foi bem sucedida e ir√° criar uma pasta no seu projeto chamada tokens, esta pasta guarda a sess√£o da conex√£o, dessa forma voce n√£o precisar√° ler o QR Code toda vez que inicializar o projeto.

![Estrutura das pastas ap√≥s instala√ß√£o do venom](https://miro.medium.com/max/614/1*3jGekQPj3WDS4BKR9d4kdA.webp)

Vamos agora testar nosso humilde script e ver se deu tudo certinho com nossa integra√ß√£o com o Venom!

![Teste do venom](https://miro.medium.com/max/720/1*CA7Dn78ZSo2M6EU5LIhenw.webp)

## 3. Instalando e configurando o ‚ÄúChat GPT‚Äù
Nada melhor do que o nosso querid√≠ssimo Chat GPT para nos explicar o significado de ‚ÄúGPT‚Äù.

> GPT √© uma sigla para ‚ÄúGenerative Pre-trained Transformer‚Äù, √© um modelo de linguagem treinado pela OpenAI. Ele √© capaz de gerar texto de forma aut√¥noma, com base em um grande conjunto de dados de texto pr√©-treinado. Ele pode ser usado para tarefas como preenchimento autom√°tico, gera√ß√£o de texto, tradu√ß√£o autom√°tica, entre outras. Ele √© uma das tecnologias de IA de linguagem mais avan√ßadas dispon√≠veis atualmente e √© utilizado em uma variedade de aplica√ß√µes, incluindo chatbots, assistentes virtuais e sistemas de gera√ß√£o autom√°tica de conte√∫do.

![Chat GPT Logo](https://miro.medium.com/max/720/1*04Y9k6eas6R0iLUNjeqIRw.webp)

### Passo 3.1: Pegar a API Key e Organization ID na OpenAI
A primeira coisa que precisamos aqui √© da api key da openai, uma chave para autoriza√ß√£o de envio das nossas requisi√ß√µes. Entre neste link para pegar sua chave https://beta.openai.com/account/api-keys, √© bem auto explicativo.

![API Key na open api](https://miro.medium.com/max/720/1*SYxpE_Es5MSC3ORTQPySNg.webp)

Para pegar o organization ID tamb√©m √© bem f√°cil, √© s√≥ acessar este link e copiar o seu ID https://beta.openai.com/account/org-settings

![Organization ID](https://miro.medium.com/max/640/1*jdI2EmPw9G0WAoL-rdBcIg.webp)

### Passo 3.2: Instala√ß√£o
Agora da mesma forma que fizemos com o venom faremos com a depend√™ncia da openai, instale-a utilizando o comando ‚Äúnpm install openai‚Äù em seu terminal na raiz do projeto.

```
# Instale openai como uma dependencia do seu projeto
npm install openai
```

Para evitarmos futuros problemas como o vazamento da nossa api key e organization id vamos instalar tamb√©m uma depencia chamada dotenv, que serve para criarmos vari√°veis de ambiente separadas do c√≥digo.

```
# Instale dotenv como uma dependencia do seu projeto
npm install dotenv
```

### Passo 3.3: Configura√ß√£o
Vamos come√ßar configurando nossas vari√°veis de ambiente com o dotenv. Na raiz do seu projeto crie um arquivo chamado ‚Äú.env‚Äù nele colocaremos quaisquer dados sens√≠veis que precisaremos utilizar em nosso projeto.

![Estrutura das pastas .env](https://miro.medium.com/max/620/1*cPviWtCaiAtkODrqcPM_3A.webp)

Dentro do arquivo iremos criar uma vari√°vel chamada OPENAI_KEY e colocaremos nossa api key aqui.

```
OPENAI_KEY=SUA-API-KEY
ORGANIZATION_ID=SEU-ORGANIZATION-ID
PHONE_NUMBER=SEU-NUMERO exemplo -> 553144448888@c.us
```

Em nosso arquivo index.js vamos carregar nossas vari√°veis para podermos utiliza-las e instanciar a configura√ß√£o da openai.

```
import { create } from 'venom-bot'
import * as dotenv from 'dotenv'
import { Configuration, OpenAIApi } from "openai"

dotenv.config()

/* Agora podemos chamar nossas vari√°veis de ambiente
 * process.env.OPENAI_KEY
 * process.env.ORGANIZATION_ID
 * process.env.PHONE_NUMBER
 */ 
const configuration = new Configuration({
    organization: process.env.ORGANIZATION_ID,
    apiKey: process.env.OPENAI_KEY,
});
```

Ap√≥s isso iremos criar 3 fun√ß√µes, a primeira *getDavinciResponse()* ser√° para fazer chamadas para o davinci-003 que ir√° gerar as respostas em texto:

```
const getDavinciResponse = async (clientText) => {
    const options = {
        model: "text-davinci-003", // Modelo GPT a ser usado
        prompt: clientText, // Texto enviado pelo usu√°rio
        temperature: 1, // N√≠vel de varia√ß√£o das respostas geradas, 1 √© o m√°ximo
        max_tokens: 4000 // Quantidade de tokens (palavras) a serem retornadas pelo bot, 4000 √© o m√°ximo
    }

    try {
        const response = await openai.createCompletion(options)
        let botResponse = ""
        response.data.choices.forEach(({ text }) => {
            botResponse += text
        })
        return `Chat GPT ü§ñ\n\n ${botResponse.trim()}`
    } catch (e) {
        return `‚ùå OpenAI Response Error: ${e.response.data.error.message}`
    }
}
```

A segunda fun√ß√£o ser√° para a DALL-E *getDalleResponse()* que ir√° gerar nossas imagens:

```
const getDalleResponse = async (clientText) => {
    const options = {
        prompt: clientText, // Descri√ß√£o da imagem
        n: 1, // N√∫mero de imagens a serem geradas
        size: "1024x1024", // Tamanho da imagem
    }

    try {
        const response = await openai.createImage(options);
        return response.data.data[0].url
    } catch (e) {
        return `‚ùå OpenAI Response Error: ${e.response.data.error.message}`
    }
}
```

A tarceira e ultima *commands()*, ser√° para mapear os comandos que chegam como input do usu√°rio:

```
const commands = (client, message) => {
    const iaCommands = {
        davinci3: "/bot",
        dalle: "/img"
    }

    let firstWord = message.text.substring(0, message.text.indexOf(" "));

    switch (firstWord) {
        case iaCommands.davinci3:
            const question = message.text.substring(message.text.indexOf(" "));
            getDavinciResponse(question).then((response) => {
                /*
                 * Faremos uma valida√ß√£o no message.from
                 * para caso a gente envie um comando
                 * a response n√£o seja enviada para
                 * nosso pr√≥prio n√∫mero e sim para 
                 * a pessoa ou grupo para o qual eu enviei
                 */
                client.sendText(message.from === process.env.BOT_NUMBER ? message.to : message.from, response)
            })
            break;

        case iaCommands.dalle:
            const imgDescription = message.text.substring(message.text.indexOf(" "));
            getDalleResponse(imgDescription, message).then((imgUrl) => {
                client.sendImage(
                    message.from === process.env.BOT_NUMBER ? message.to : message.from,
                    imgUrl,
                    imgDescription,
                    'Imagem gerada pela IA DALL-E ü§ñ'
                )
            })
            break;
    }
}
```

Por fim iremos listar dentro do nosso callback do evento *onAnyMessage()* a fun√ß√£o *commands()*. O nosso index.js ficar√° exatamente como mostrado abaixo!

```
import { create } from 'venom-bot'
import * as dotenv from 'dotenv'
import { Configuration, OpenAIApi } from "openai"

dotenv.config()

create({
    session: 'Chat-GPT',
    multidevice: true
})
    .then((client) => start(client))
    .catch((erro) => {
        console.log(erro);
    });

const configuration = new Configuration({
    organization: process.env.ORGANIZATION_ID,
    apiKey: process.env.OPENAI_KEY,
});

const openai = new OpenAIApi(configuration);

const getDavinciResponse = async (clientText) => {
    const options = {
        model: "text-davinci-003", // Modelo GPT a ser usado
        prompt: clientText, // Texto enviado pelo usu√°rio
        temperature: 1, // N√≠vel de varia√ß√£o das respostas geradas, 1 √© o m√°ximo
        max_tokens: 4000 // Quantidade de tokens (palavras) a serem retornadas pelo bot, 4000 √© o m√°ximo
    }

    try {
        const response = await openai.createCompletion(options)
        let botResponse = ""
        response.data.choices.forEach(({ text }) => {
            botResponse += text
        })
        return `Chat GPT ü§ñ\n\n ${botResponse.trim()}`
    } catch (e) {
        return `‚ùå OpenAI Response Error: ${e.response.data.error.message}`
    }
}

const getDalleResponse = async (clientText) => {
    const options = {
        prompt: clientText, // Descri√ß√£o da imagem
        n: 1, // N√∫mero de imagens a serem geradas
        size: "1024x1024", // Tamanho da imagem
    }

    try {
        const response = await openai.createImage(options);
        return response.data.data[0].url
    } catch (e) {
        return `‚ùå OpenAI Response Error: ${e.response.data.error.message}`
    }
}

const commands = (client, message) => {
    const iaCommands = {
        davinci3: "/bot",
        dalle: "/img"
    }

    let firstWord = message.text.substring(0, message.text.indexOf(" "));

    switch (firstWord) {
        case iaCommands.davinci3:
            const question = message.text.substring(message.text.indexOf(" "));
            getDavinciResponse(question).then((response) => {
                /*
                 * Faremos uma valida√ß√£o no message.from
                 * para caso a gente envie um comando
                 * a response n√£o seja enviada para
                 * nosso pr√≥prio n√∫mero e sim para 
                 * a pessoa ou grupo para o qual eu enviei
                 */
                client.sendText(message.from === process.env.BOT_NUMBER ? message.to : message.from, response)
            })
            break;

        case iaCommands.dalle:
            const imgDescription = message.text.substring(message.text.indexOf(" "));
            getDalleResponse(imgDescription, message).then((imgUrl) => {
                client.sendImage(
                    message.from === process.env.BOT_NUMBER ? message.to : message.from,
                    imgUrl,
                    imgDescription,
                    'Imagem gerada pela IA DALL-E ü§ñ'
                )
            })
            break;
    }
}

async function start(client) {
    client.onAnyMessage((message) => commands(client, message));
}
```

### Passo 3.4: Hora de testar!

![Teste da implementa√ß√£o](https://miro.medium.com/max/720/1*0K0tAo1ujQoFa9NG3ClIdw.webp)

## 4. Considera√ß√µes finais
Se te ajudei de alguma forma j√° curte esse guia para que ele chegue em mais pessoas e as ajude tamb√©m!

### 4.1 Dicas
Voce pode subir esse servi√ßo em uma m√°quina EC2 da AWS Amazon para que ele fique 24/7 ( rodando 24h por dia ) gratuitamente por 1 ano! Assim voce n√£o precisa pagar mais caro na sua conta de luz com seu PC Gamer com RPG ligado a semana toda!

Caso seja do seu interesse se inscreve l√° no meu canal, n√£o tem nada ainda mas em breve vou soltar v√≠deos explicando passo a passo de como fazer essa instala√ß√£o do projeto em um servidor da EC2, e tamb√©m criarei outros conte√∫dos legais como desse post!

[Canal Dev Cansado](https://www.youtube.com/@devcansadodms)

### 4.2 Ta com pregui√ßa e quer um plug and play?
Sei que eu deveria colocar isso no in√≠cio pra evitar da galera descobrir s√≥ depois de ler tudo mas voc√™ tamb√©m deveria ler mais üëç

Vai l√° no reposit√≥rio e da fork: https://github.com/victorharry/zap-gpt

### 4.3 Sugest√µes
Caso tenha uma ideia de como otimizar o c√≥digo e deixar ele mais leg√≠vel  pode deixar aqui comentado ou abre um MR l√° no repo que a gente atualiza pra ficar bacana pra todo mundo e pra gente trocar conhecimento tamb√©m, sempre bom! 

Valeu polvo üêô

Quem quiser conectar no [Linkedin](https://www.linkedin.com/in/victorhcharry/)

![Comemora√ß√µes](https://miro.medium.com/max/720/1*T-sT0gthpO-a_GMkERUCMw.webp)

*Deixei a fonte com o link do Medium pois postei l√° antes*
